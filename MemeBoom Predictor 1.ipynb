{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ef4dde",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1b41e",
   "metadata": {},
   "source": [
    "This project involves building a regression model in PySpark to predict the viral potential of social media memes, measured as an Engagement Score based on likes, shares, and comments. The model leverages features such as Image Complexity, Text Length, Posting Hour, Follower Count, Meme Category, and Platform, using techniques like one-hot encoding, feature scaling, and imputation to handle missing data. The dataset, sourced from meme-sharing platforms like Reddit, Instagram, and X, includes both numeric and categorical variables, enabling the model to capture cultural and contextual factors influencing meme virality. The goal is to provide actionable insights for content creators and marketers by predicting meme performance before posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265feac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('MemeBoom Predictor 1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54ae40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_data = spark.read.csv(\"../Data/meme_dataset.csv\", header =True, inferSchema =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace9830d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+------------+--------------+-------------+---------+\n",
      "|Engagement Score|Image Complexity|Text Length|Posting Hour|Follower Count|Meme Category| Platform|\n",
      "+----------------+----------------+-----------+------------+--------------+-------------+---------+\n",
      "|     59.93428306|           0.692|         23|          10|        176299|    wholesome|   Reddit|\n",
      "|     47.23471398|           0.426|         19|          19|        545315|     reaction|   TikTok|\n",
      "|     62.95377076|           0.384|         27|          21|         96373|         dark|Instagram|\n",
      "|     80.46059713|           0.687|         30|          13|          2258|    relatable|Instagram|\n",
      "|     45.31693251|          -0.046|         25|          22|        453061|       satire|        X|\n",
      "|     45.31726086|           0.245|         19|          10|        849414|    relatable|   Reddit|\n",
      "|     81.58425631|           0.549|         20|           0|        479100|    wholesome|        X|\n",
      "|     65.34869458|           0.668|         18|          21|        588861|    wholesome|        X|\n",
      "|     40.61051228|            NULL|         19|           3|        413838|    relatable|   TikTok|\n",
      "|     60.85120087|          -0.045|         23|          14|        959504|    wholesome|Instagram|\n",
      "|     40.73164614|           0.403|         22|          18|        960362|       satire|        X|\n",
      "|     40.68540493|           0.672|         16|           2|        845432|       absurd|   Reddit|\n",
      "|     54.83924543|           0.295|         17|          12|        958910|       absurd|Instagram|\n",
      "|     11.73439511|           0.453|         22|           0|        293288|       absurd| Facebook|\n",
      "|     15.50164335|            0.59|         24|           3|        548627|    wholesome|   Reddit|\n",
      "|     38.75424942|           0.513|         19|          11|         11704|       absurd|   Reddit|\n",
      "|     29.74337759|           0.598|         25|          22|        150751|    wholesome|   Reddit|\n",
      "|     56.28494665|           0.465|         18|           7|         51948|       satire|        X|\n",
      "|     31.83951849|           0.614|         19|          18|         38431|    wholesome|   TikTok|\n",
      "|     21.75392597|           0.619|         16|          21|        598448|    political| Facebook|\n",
      "+----------------+----------------+-----------+------------+--------------+-------------+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "meme_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfba2497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[Engagement Score: double, Image Complexity: double, Text Length: int, Posting Hour: int, Follower Count: int, Meme Category: string, Platform: string]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_data.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3b2e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+------------+--------------+-------------+--------+\n",
      "|Engagement Score|Image Complexity|Text Length|Posting Hour|Follower Count|Meme Category|Platform|\n",
      "+----------------+----------------+-----------+------------+--------------+-------------+--------+\n",
      "|               4|               3|          6|           4|             1|            2|       2|\n",
      "+----------------+----------------+-----------+------------+--------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "meme_data.select([count(when(col(c).isNull(),c)).alias(c) for c in meme_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0ccc3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = meme_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fcd1a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+-----------+------------+--------------+-------------+--------+\n",
      "|Engagement Score|Image Complexity|Text Length|Posting Hour|Follower Count|Meme Category|Platform|\n",
      "+----------------+----------------+-----------+------------+--------------+-------------+--------+\n",
      "|               0|               0|          0|           0|             0|            0|       0|\n",
      "+----------------+----------------+-----------+------------+--------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.select([count(when(col(c).isNull(),c)).alias(c) for c in clean_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05cba003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-----------------+------------------+------------------+-------------+--------+\n",
      "|summary|  Engagement Score|   Image Complexity|      Text Length|      Posting Hour|    Follower Count|Meme Category|Platform|\n",
      "+-------+------------------+-------------------+-----------------+------------------+------------------+-------------+--------+\n",
      "|  count|             89978|              89978|            89978|             89978|             89978|        89978|   89978|\n",
      "|   mean| 50.03592064727755|0.38724824957264936|19.98128431394341|11.498944186356665|499883.14123452397|         NULL|    NULL|\n",
      "| stddev|19.802773907281697|0.17993630535247407| 4.46479435102178| 6.914074133713424| 288903.1315864442|         NULL|    NULL|\n",
      "|    min|               0.0|               -0.3|                2|                 0|               103|       absurd|Facebook|\n",
      "|    max|             100.0|               1.34|               42|                23|            999993|    wholesome|       X|\n",
      "+-------+------------------+-------------------+-----------------+------------------+------------------+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62c20cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "# StringIndexer for Meme Category\n",
    "category_indexer = StringIndexer(inputCol=\"Meme Category\", outputCol=\"MemeCategoryIndex\")\n",
    "category_encoder = OneHotEncoder(inputCols=[\"MemeCategoryIndex\"], outputCols=[\"MemeCategoryVec\"])\n",
    "\n",
    "# StringIndexer for Platform\n",
    "platform_indexer = StringIndexer(inputCol=\"Platform\", outputCol=\"PlatformIndex\")\n",
    "platform_encoder = OneHotEncoder(inputCols=[\"PlatformIndex\"], outputCols=[\"PlatformVec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d30dacd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Follower Count (optional, using StandardScaler)\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"Follower Count\"], outputCol=\"FollowerCountVec\")\n",
    "scaler = StandardScaler(inputCol=\"FollowerCountVec\", outputCol=\"ScaledFollowerCount\", withStd=True, withMean=True)\n",
    "\n",
    "# Combine all features\n",
    "feature_columns = [\"Image Complexity\", \"Text Length\", \"Posting Hour\", \"ScaledFollowerCount\", \"MemeCategoryVec\", \"PlatformVec\"]\n",
    "final_assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69ee0828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "# Initialize Linear Regression\n",
    "regressor = LinearRegression(featuresCol = \"features\", labelCol = \"Engagement Score\")\n",
    "\n",
    "#Creating a pipeline\n",
    "pipeline = Pipeline(stages=[category_indexer, category_encoder, platform_indexer, platform_encoder, assembler, scaler, final_assembler, regressor])\n",
    "\n",
    "#Split data into training and test sets\n",
    "train_data, test_data = clean_data.randomSplit([0.8,0.2], seed = 42)\n",
    "\n",
    "#Fit the model\n",
    "meme_data_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1432d331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 19.5161281868429\n",
      "R² Score: -6.569830206903937e-05\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Make predictions\n",
    "predictions = meme_data_model.transform(test_data)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"Engagement Score\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"Engagement Score\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070c664c",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edc0ce",
   "metadata": {},
   "source": [
    "For every meme in the test set, the model’s predictions are, on average, off by about 19.5 units of Engagement Score, which is significant given the score’s range of approximately 11 to 81. The negative R² score means the model is less accurate than simply predicting the average Engagement Score for every meme, suggesting it fails to capture meaningful patterns in features like Image Complexity, Follower Count, or Meme Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23060620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
